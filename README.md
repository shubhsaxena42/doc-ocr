<div align="center">

# ğŸšœ IDAI â€” Intelligent Document AI Pipeline

### Automated tractor loan invoice extraction at **â‰¥95% accuracy**, **<$0.01/doc**, **<30s latency**

*A production-grade MLOps pipeline that runs ensemble OCR, YOLOv8 visual detection, and a 3-tier LLM adjudication ladder â€” deployed as isolated Docker microservices to eliminate dependency conflicts entirely.*

---

![Python](https://img.shields.io/badge/Python-3.10-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)
![PaddleOCR](https://img.shields.io/badge/PaddleOCR-2.7.3-red)
![DeepSeek](https://img.shields.io/badge/DeepSeek--OCR-4bit%20NF4-blueviolet)
![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-00FFFF?logo=github)
![Qwen](https://img.shields.io/badge/Qwen2.5--VL-7B-orange)
![License](https://img.shields.io/badge/License-Proprietary-lightgrey)

</div>

---

## âš¡ What Problem Does This Solve?

Indian banks and NBFCs processing tractor loan applications manually re-key data from handwritten/scanned invoices â€” a process that takes **~8 minutes per document**, costs ~â‚¹50 in manual labour, and runs at **~70% accuracy** due to human error.

**IDAI automates this end-to-end:**

> Feed in a scanned invoice â†’ get back a structured JSON with dealer name, model, HP, cost, and confirmed signature/stamp â€” in under 30 seconds, at sub-cent cost, with â‰¥95% accuracy.

---

## ğŸ“Š Results at a Glance

| Metric | Target | Notes |
|:---|:---:|:---|
| **Document-Level Accuracy (DLA)** | **â‰¥ 95%** | All 6 fields correct per document |
| **Cost per Document** | **< $0.01** | Local models; VLM invoked <10% of the time |
| **End-to-End Latency** | **< 30s** | OCR runs in parallel; tiers short-circuit on agreement |
| **VLM Invocation Rate** | **< 10%** | Most conflicts resolved by cheap Rules/SLM tiers |

---

## ğŸ—ï¸ Architecture

### The Core Insight â€” Microservice Isolation for Dependency Conflicts

PaddleOCR requires `transformersâ‰¤4.37` but DeepSeek-OCR requires `transformersâ‰¥4.40`. Running both in one Python environment causes import crashes. The industry-standard solution is **process isolation via containers**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           docker-compose.yml                            â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   paddle-ocr :5001   â”‚      â”‚      deepseek-ocr :5002      â”‚         â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚      â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚         â”‚
â”‚  â”‚  transformers 4.37.2 â”‚      â”‚  transformers 4.40.2         â”‚         â”‚
â”‚  â”‚  paddlepaddle 2.5.2  â”‚      â”‚  bitsandbytes (4-bit NF4)   â”‚         â”‚
â”‚  â”‚  Flask  /ocr POST    â”‚      â”‚  Flash  /ocr POST            â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚             â”‚   concurrent HTTP POST /ocr    â”‚                          â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                            â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    pipeline (main app)                          â”‚    â”‚
â”‚  â”‚                                                                 â”‚    â”‚
â”‚  â”‚   Image â”€â”€â–¶ [OCR Clients]â”€â”€â–¶ [Consensus] â”€â”€â–¶ [Adjudication]    â”‚    â”‚
â”‚  â”‚                 âˆ¥                                  âˆ¥            â”‚    â”‚
â”‚  â”‚            parallel HTTP              Tier 1: Rules (0ms, $0)  â”‚    â”‚
â”‚  â”‚                 +                     Tier 2: SLM-3B  (~5s)    â”‚    â”‚
â”‚  â”‚            YOLOv8 Visual              Tier 3: VLM-7B  (~15s)   â”‚    â”‚
â”‚  â”‚            Detection                                            â”‚    â”‚
â”‚  â”‚                                    â”€â”€â–¶ Calibration â”€â”€â–¶ JSON    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow (Step-by-Step)

```mermaid
flowchart LR
    A[ğŸ“„ Scan / PDF] --> B(Image Pre-processing)

    B --> C["ğŸ”µ PaddleOCR\n:5001 Â· transformers 4.37"]
    B --> D["ğŸŸ£ DeepSeek-OCR\n:5002 Â· transformers 4.40\n4-bit NF4"]
    B --> E["ğŸŸ¡ YOLOv8\nSignature + Stamp\nDetection"]

    C --> F{Consensus\nEngine}
    D --> F
    E --> F

    F -->|Agreement| G[âœ… Tier 0\nDirect Output]
    F -->|Conflict| H["âš¡ Tier 1\nRegex Rules\n$0, <1ms"]
    H -->|Unresolved| I["ğŸ§  Tier 2  SLM\nQwen2.5-3B-Instruct\n4-bit Â· ~5s"]
    I -->|Uncertain| J["ğŸ‘ï¸ Tier 3  VLM\nQwen2.5-VL-7B-Instruct\n4-bit Â· ~15s"]

    G & H & I & J --> K["ğŸ“ Isotonic\nCalibration"]
    K --> L["ğŸ“¦ results.json"]
```

---

## ğŸ› ï¸ Tech Stack & Design Decisions

| Layer | Technology | Why This, Not That |
|:---|:---|:---|
| **OCR Ensemble** | PaddleOCR + DeepSeek-OCR | Two independent OCR engines give a consensus signal â€” more reliable than either alone |
| **OCR Isolation** | Docker microservices (Flask) | Solves `transformers` version conflict without virtual envs or subprocess hacks; production-friendly and independently scalable |
| **Visual Detection** | YOLOv8 (ONNX) | ONNX runtime has no CUDA dependency â€” runs on any hardware; fast enough for real-time |
| **Tier 2 Adjudicator** | Qwen2.5-3B-Instruct (4-bit) | 3B fits on a single T4 GPU; handles 90%+ of conflicts; replaces a 70B model call |
| **Tier 3 Adjudicator** | Qwen2.5-VL-7B-Instruct (4-bit) | Only invoked for visually ambiguous fields; multimodal reasoning on cropped image regions |
| **Calibration** | Isotonic regression | Non-parametric; monotonic; fits confidence scores with small calibration datasets |
| **Fuzzy Matching** | RapidFuzz | 10-100Ã— faster than `difflib`; handles OCR typos in dealer names against master list |
| **Orchestration** | Docker Compose v2 | Single-command spin-up with health checks and GPU reservation â€” reproducible anywhere |

---

## ğŸ§± Engineering Challenges & Trade-offs

### Challenge 1 â€” The `transformers` Version Conflict
**Problem:** PaddleOCR's internal inference code imports `transformers` at `<=4.37`. DeepSeek-OCR needs `>=4.40` for its quantization API. Both in the same venv â†’ immediate import crash.

**Solution Considered & Rejected:** `subprocess` isolation with a separate Python binary â€” brittle, hard to debug, non-standard.

**Solution Chosen:** Full Docker microservice isolation. Each OCR engine is a lightweight Flask server (`POST /ocr`, returns JSON). The main pipeline has **zero direct OCR imports** â€” it's a pure HTTP client. This is how production ML systems are actually built.

### Challenge 2 â€” Cost vs. Accuracy Trade-off
**Problem:** Running a 70B+ VLM on every document would blow past the $0.01/doc budget.

**Solution:** 3-tier escalation ladder. ~80% of documents are resolved in Tier 1 (instantaneous regex rules, $0). ~10% require the SLM (~$0.001 per call). Only ~5-10% of the hardest cases reach the VLM. Average cost stays well under the budget.

### Challenge 3 â€” Visual Field Verification
**Problem:** OCR engines produce text only â€” they cannot confirm if a signature or stamp is **physically present** on the document.

**Solution:** YOLOv8 detectors (trained on annotated invoice images) output bounding boxes + confidence scores. A geometric verification layer cross-checks detected regions against expected layout zones before accepting a visual field as confirmed.

---

## ğŸš€ Quick Start

### Prerequisites
- Docker + Docker Compose v2
- NVIDIA GPU + `nvidia-container-toolkit` (for DeepSeek-OCR and VLM)
- ~20 GB free disk (model weights downloaded on first run)

### One-Command Start

```bash
git clone <repo>
cd idai-pipeline

# Build all 3 containers and start services
docker compose up --build
```

### Run Inference

```bash
# Full pipeline (all 3 tiers)
docker compose run pipeline \
  --input /app/train \
  --output /app/output/results.json \
  --mode full

# CPU-lite mode (skips Tier 3 VLM â€” faster, cheaper)
docker compose run pipeline \
  --input /app/train \
  --output /app/output/results.json \
  --mode cpu-lite
```

### Local Development (No Docker)

```bash
# Terminal 1: PaddleOCR service (transformers 4.37.x env)
cd services/paddle_ocr && pip install -r requirements.txt
python app.py            # â†’ http://localhost:5001

# Terminal 2: DeepSeek-OCR service (transformers 4.40.x env)
cd services/deepseek_ocr && pip install -r requirements.txt
python app.py            # â†’ http://localhost:5002

# Terminal 3: Main pipeline
pip install -r requirements.txt
PADDLE_OCR_URL=http://localhost:5001 \
DEEPSEEK_OCR_URL=http://localhost:5002 \
python executable.py --input ./train --output results.json --mode full
```

### Evaluate

```bash
python evaluate.py \
  --predictions output/results.json \
  --golden data/golden_set.json
```

Outputs: DLA, per-field accuracy, mAP (IoU>0.5), cost breakdown, VLM invocation rate.

---

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ docker-compose.yml        â† Orchestrates all 3 containers
â”œâ”€â”€ Dockerfile                â† Main pipeline image
â”œâ”€â”€ requirements.txt          â† No OCR deps; just requests + LLM stack
â”œâ”€â”€ config.py                 â† Central config (service URLs, thresholds)
â”œâ”€â”€ executable.py             â† CLI entry point
â”œâ”€â”€ evaluate.py               â† DLA + cost evaluation
â”œâ”€â”€ evaluate_results.py       â† Field-level evaluation
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ paddle_ocr/
â”‚   â”‚   â”œâ”€â”€ Dockerfile        â† python:3.10-slim + transformers 4.37
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ app.py            â† Flask: POST /ocr  GET /health
â”‚   â””â”€â”€ deepseek_ocr/
â”‚       â”œâ”€â”€ Dockerfile        â† nvidia/cuda + transformers 4.40
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ app.py            â† Flask: POST /ocr  GET /health
â”‚
â””â”€â”€ pipeline/
    â”œâ”€â”€ ocr_engines.py        â† HTTP client (no direct OCR imports)
    â”œâ”€â”€ main_pipeline.py      â† Orchestration
    â”œâ”€â”€ consensus.py          â† Conflict detection & field voting
    â”œâ”€â”€ adjudicator.py        â† 3-tier escalation logic
    â”œâ”€â”€ slm_judge.py          â† Tier 2: Qwen2.5-3B
    â”œâ”€â”€ vlm_judge.py          â† Tier 3: Qwen2.5-VL-7B
    â”œâ”€â”€ detectors.py          â† YOLOv8 ONNX inference
    â”œâ”€â”€ field_parser.py       â† Regex field extraction
    â”œâ”€â”€ calibration.py        â† Isotonic confidence calibration
    â”œâ”€â”€ cost_tracker.py       â† Per-run cost & latency logging
    â””â”€â”€ json_logger.py        â† Structured output
```

---

## ğŸ’° Cost & Latency Breakdown

| Component | Cost | Latency | Invocation Rate |
|:---|:---:|:---:|:---:|
| PaddleOCR Service (local) | $0 | ~2.5s | 100% |
| DeepSeek-OCR Service (local, 4-bit) | $0 | ~2.5s | 100% |
| YOLOv8 Detection (ONNX, local) | $0 | ~3s | 100% |
| Tier 1 â€” Rules | $0 | <1ms | ~80% of conflicts |
| Tier 2 â€” SLM (Qwen 3B, 4-bit) | ~$0.001/call | ~5s | ~15% of conflicts |
| Tier 3 â€” VLM (Qwen-VL 7B, 4-bit) | ~$0.02/call | ~15s | ~5% of conflicts |
| **Average Total** | **<$0.01** | **<30s** | â€” |

---

## ğŸ“‘ Extracted Fields

| Field | Type | Resolution Strategy |
|:---|:---:|:---|
| `dealer_name` | Text | Fuzzy match (RapidFuzz) against master list â†’ SLM if ambiguous |
| `model_name` | Text | Consensus OCR â†’ SLM for conflicts |
| `horse_power` | Numeric | Regex extraction + numeric range validation |
| `asset_cost` | Numeric | Regex extraction + outlier detection (Â±20% of segment avg) |
| `signature` | Visual | YOLOv8 detection + geometric zone verification |
| `stamp` | Visual | YOLOv8 detection + colour-range HSV filter |

---

## âš™ï¸ Configuration Reference

### Service URLs (set via environment variables or `config.py`)

| Variable | Default | Description |
|:---|:---|:---|
| `PADDLE_OCR_URL` | `http://localhost:5001` | PaddleOCR service base URL |
| `DEEPSEEK_OCR_URL` | `http://localhost:5002` | DeepSeek-OCR service base URL |
| `OCR_TIMEOUT` | `120` | HTTP timeout in seconds |

### Models

| Role | Model | Quantization |
|:---|:---|:---|
| OCR Engine A | PaddleOCR (en) | Full precision |
| OCR Engine B | DeepSeek-OCR | 4-bit NF4 |
| Tier 2 Judge | Qwen2.5-3B-Instruct | 4-bit NF4 via bitsandbytes |
| Tier 3 Judge | Qwen2.5-VL-7B-Instruct | 4-bit NF4 via bitsandbytes |
| Visual Detector | YOLOv8 (custom) | ONNX FP32 |

---

## ğŸ§ª Running Tests

```bash
python -m pytest tests/ -v --tb=short
```

---

## ğŸ“„ License

Proprietary â€” Hackathon Submission (IDFC First Bank AI Challenge)
