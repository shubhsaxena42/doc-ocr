{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14574915,"sourceType":"datasetVersion","datasetId":9310165}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Document AI Pipeline with LLM-in-the-Loop\n\n**Architecture:**\n- **OCR**: DeepSeek-OCR (4-bit quantized) or PaddleOCR\n- **Signature Detection**: YOLOv8\n- **Stamp Detection**: Hardcoded placeholder\n- **LLM Extraction**: Qwen2.5-3B-Instruct (4-bit)","metadata":{}},{"cell_type":"markdown","source":"## 1. Setup","metadata":{}},{"cell_type":"code","source":"!pip install paddlepaddle paddleocr ultralytics huggingface_hub pdf2image transformers accelerate bitsandbytes addict -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:22:30.581309Z","iopub.execute_input":"2026-01-22T04:22:30.581724Z","iopub.status.idle":"2026-01-22T04:23:02.907909Z","shell.execute_reply.started":"2026-01-22T04:22:30.581683Z","shell.execute_reply":"2026-01-22T04:23:02.907190Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.7/193.7 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nydata-profiling 4.18.1 requires PyYAML<6.1,>=6.0.3, but you have pyyaml 6.0.2 which is incompatible.\nlangchain-core 0.3.79 requires packaging<26.0.0,>=23.2.0, but you have packaging 26.0rc2 which is incompatible.\ngradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.5 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nfastai 2.8.4 requires fastcore<1.9,>=1.8.0, but you have fastcore 1.11.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers==4.47.1 -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:02.909603Z","iopub.execute_input":"2026-01-22T04:23:02.910086Z","iopub.status.idle":"2026-01-22T04:23:21.385361Z","shell.execute_reply.started":"2026-01-22T04:23:02.910054Z","shell.execute_reply":"2026-01-22T04:23:21.384669Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:24:40.262303Z","iopub.execute_input":"2026-01-22T04:24:40.263087Z","iopub.status.idle":"2026-01-22T04:24:40.325055Z","shell.execute_reply.started":"2026-01-22T04:24:40.263041Z","shell.execute_reply":"2026-01-22T04:24:40.324516Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import os\nimport tempfile\nimport io\nimport sys\nimport re\n\nos.environ[\"FLAGS_use_mkldnn\"] = \"0\"\nos.environ[\"FLAGS_enable_pir_executor\"] = \"0\"\nos.environ[\"FLAGS_use_mkl\"] = \"0\"\nos.environ[\"MKLDNN_DISABLE\"] = \"1\"\nos.environ[\"FLAGS_enable_pir_api\"] = \"0\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:21.386447Z","iopub.execute_input":"2026-01-22T04:23:21.386763Z","iopub.status.idle":"2026-01-22T04:23:21.391581Z","shell.execute_reply.started":"2026-01-22T04:23:21.386721Z","shell.execute_reply":"2026-01-22T04:23:21.390981Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import json\nimport time\nfrom pathlib import Path\nfrom enum import Enum\nimport cv2\nimport numpy as np\nimport torch\nfrom PIL import Image\n\nfrom ultralytics import YOLO\nfrom huggingface_hub import hf_hub_download\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, BitsAndBytesConfig\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:21.392712Z","iopub.execute_input":"2026-01-22T04:23:21.393006Z","iopub.status.idle":"2026-01-22T04:23:32.235403Z","shell.execute_reply.started":"2026-01-22T04:23:21.392981Z","shell.execute_reply":"2026-01-22T04:23:32.234626Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nPyTorch: 2.8.0+cu126\nCUDA: True\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 2. Configuration","metadata":{}},{"cell_type":"code","source":"class OCREngine(Enum):\n    PADDLE = \"paddleocr\"\n    DEEPSEEK = \"deepseek-ocr\"\n\n# âš™ï¸ SELECT OCR ENGINE\nACTIVE_OCR_ENGINE = OCREngine.DEEPSEEK\n\n# âš™ï¸ LLM Quantization\nLLM_QUANTIZE_4BIT = True\n\nprint(f\"ğŸ”§ OCR: {ACTIVE_OCR_ENGINE.value}\")\nprint(f\"ğŸ”§ LLM 4-bit: {LLM_QUANTIZE_4BIT}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:32.236455Z","iopub.execute_input":"2026-01-22T04:23:32.237012Z","iopub.status.idle":"2026-01-22T04:23:32.242098Z","shell.execute_reply.started":"2026-01-22T04:23:32.236981Z","shell.execute_reply":"2026-01-22T04:23:32.241481Z"}},"outputs":[{"name":"stdout","text":"ğŸ”§ OCR: deepseek-ocr\nğŸ”§ LLM 4-bit: True\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Global models\npaddle_ocr = None\ndeepseek_ocr_model = None\ndeepseek_ocr_tokenizer = None\nsignature_model = None\nllm_model = None\nllm_tokenizer = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:32.242919Z","iopub.execute_input":"2026-01-22T04:23:32.243194Z","iopub.status.idle":"2026-01-22T04:23:32.259359Z","shell.execute_reply.started":"2026-01-22T04:23:32.243168Z","shell.execute_reply":"2026-01-22T04:23:32.258648Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 3. Load Models","metadata":{}},{"cell_type":"code","source":"def load_paddle_ocr():\n    global paddle_ocr\n    from paddleocr import PaddleOCR\n    print(\"ğŸ”„ Loading PaddleOCR...\")\n    start = time.time()\n    paddle_ocr = PaddleOCR(use_textline_orientation=True, lang='en', enable_mkldnn=False)\n    print(f\"âœ“ PaddleOCR loaded in {time.time() - start:.2f}s\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:32.261672Z","iopub.execute_input":"2026-01-22T04:23:32.262207Z","iopub.status.idle":"2026-01-22T04:23:32.274445Z","shell.execute_reply.started":"2026-01-22T04:23:32.262168Z","shell.execute_reply":"2026-01-22T04:23:32.273687Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def load_deepseek_ocr():\n    \"\"\"Load pre-quantized 4-bit DeepSeek-OCR\"\"\"\n    global deepseek_ocr_model, deepseek_ocr_tokenizer\n    \n    model_id = 'Jalea96/DeepSeek-OCR-bnb-4bit-NF4'\n    print(f\"ğŸ”„ Loading DeepSeek-OCR (4-bit): {model_id}...\")\n    start = time.time()\n    \n    deepseek_ocr_tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n    deepseek_ocr_model = AutoModel.from_pretrained(\n        model_id,\n        _attn_implementation='eager',\n        trust_remote_code=True,\n        use_safetensors=True,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16\n    )\n    deepseek_ocr_model = deepseek_ocr_model.eval()\n    \n    print(f\"âœ“ DeepSeek-OCR loaded in {time.time() - start:.2f}s\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:32.275362Z","iopub.execute_input":"2026-01-22T04:23:32.275735Z","iopub.status.idle":"2026-01-22T04:23:32.290357Z","shell.execute_reply.started":"2026-01-22T04:23:32.275709Z","shell.execute_reply":"2026-01-22T04:23:32.289737Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def load_signature_detector():\n    global signature_model\n    print(\"ğŸ”„ Loading signature detector...\")\n    start = time.time()\n    model_path = hf_hub_download(repo_id=\"tech4humans/yolov8s-signature-detector\", filename=\"yolov8s.pt\")\n    signature_model = YOLO(model_path)\n    print(f\"âœ“ Signature model loaded in {time.time() - start:.2f}s\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:32.291077Z","iopub.execute_input":"2026-01-22T04:23:32.291324Z","iopub.status.idle":"2026-01-22T04:23:32.309023Z","shell.execute_reply.started":"2026-01-22T04:23:32.291300Z","shell.execute_reply":"2026-01-22T04:23:32.308427Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def load_llm(model_id=\"Qwen/Qwen2.5-Coder-0.5B-Instruct\"):\n    \"\"\"Load LLM with 4-bit quantization\"\"\"\n    global llm_model, llm_tokenizer\n    \n    quant_str = \"4-bit\" if LLM_QUANTIZE_4BIT else \"fp16\"\n    print(f\"ğŸ”„ Loading LLM: {model_id} ({quant_str})...\")\n    start = time.time()\n    \n    llm_tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n    \n    if LLM_QUANTIZE_4BIT:\n        quant_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_use_double_quant=True\n        )\n        llm_model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            quantization_config=quant_config,\n            device_map=\"auto\",\n            trust_remote_code=True\n        )\n    else:\n        llm_model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.float16,\n            device_map=\"auto\",\n            trust_remote_code=True\n        )\n    \n    print(f\"âœ“ LLM loaded in {time.time() - start:.2f}s\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:23:32.309908Z","iopub.execute_input":"2026-01-22T04:23:32.310222Z","iopub.status.idle":"2026-01-22T04:23:32.325057Z","shell.execute_reply.started":"2026-01-22T04:23:32.310184Z","shell.execute_reply":"2026-01-22T04:23:32.324299Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load all models\nif ACTIVE_OCR_ENGINE == OCREngine.PADDLE:\n    load_paddle_ocr()\nelse:\n    load_deepseek_ocr()\n\nload_signature_detector()\nload_llm()\nprint(\"\\nâœ… All models loaded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:24:46.475173Z","iopub.execute_input":"2026-01-22T04:24:46.475794Z","iopub.status.idle":"2026-01-22T04:25:16.876953Z","shell.execute_reply.started":"2026-01-22T04:24:46.475761Z","shell.execute_reply":"2026-01-22T04:25:16.876324Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Loading DeepSeek-OCR (4-bit): Jalea96/DeepSeek-OCR-bnb-4bit-NF4...\n","output_type":"stream"},{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n","output_type":"stream"},{"name":"stdout","text":"âœ“ DeepSeek-OCR loaded in 20.58s\nğŸ”„ Loading signature detector...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"yolov8s.pt:   0%|          | 0.00/22.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9792a0a707bb4b278e5dd8c7250d0e7a"}},"metadata":{}},{"name":"stdout","text":"âœ“ Signature model loaded in 0.88s\nğŸ”„ Loading LLM: Qwen/Qwen2.5-Coder-0.5B-Instruct (4-bit)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36fa5100b3434fe68c1b41dc92b923b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91ed6bfffaa14608af88efb4b8be587e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d138ea2769374c8e89c9060699c1e49d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f266219036424eaf87602d5c126ebc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3498957f97994dd28a31aaf6c2217803"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"640d11d134e840048acb976ef7e1dd6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a7c7476e0ac46c09c4fc8327c84ac53"}},"metadata":{}},{"name":"stdout","text":"âœ“ LLM loaded in 8.94s\n\nâœ… All models loaded!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## 4. Core Functions","metadata":{}},{"cell_type":"code","source":"def run_paddle_ocr(image_path: str) -> str:\n    result = paddle_ocr.predict(image_path)\n    if not result or not result[0]:\n        return \"\"\n    return \"\\n\".join([line[1][0] for line in result[0]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:19.568914Z","iopub.execute_input":"2026-01-22T04:25:19.569227Z","iopub.status.idle":"2026-01-22T04:25:19.573790Z","shell.execute_reply.started":"2026-01-22T04:25:19.569198Z","shell.execute_reply":"2026-01-22T04:25:19.573024Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def run_deepseek_ocr(image_path: str, mode: str = \"gundam\") -> str:\n    \"\"\"Extract text using DeepSeek-OCR 4-bit\"\"\"\n    mode_configs = {\n        \"tiny\":   {\"base_size\": 512, \"image_size\": 512, \"crop_mode\": False},\n        \"small\":  {\"base_size\": 640, \"image_size\": 640, \"crop_mode\": False},\n        \"base\":   {\"base_size\": 1024, \"image_size\": 1024, \"crop_mode\": False},\n        \"large\":  {\"base_size\": 1280, \"image_size\": 1280, \"crop_mode\": False},\n        \"gundam\": {\"base_size\": 1024, \"image_size\": 640, \"crop_mode\": True},\n    }\n    config = mode_configs.get(mode, mode_configs[\"gundam\"])\n    \n    prompt = \"<image>\\n<|grounding|>Convert the document to markdown. \"\n    temp_dir = os.path.join(tempfile.gettempdir(), \"deepseek_ocr_temp\")\n    if not os.path.exists(temp_dir):\n        os.makedirs(temp_dir)\n    \n    old_stdout = sys.stdout\n    sys.stdout = captured = io.StringIO()\n    \n    try:\n        result = deepseek_ocr_model.infer(\n            deepseek_ocr_tokenizer,\n            prompt=prompt,\n            image_file=image_path,\n            output_path=temp_dir,\n            base_size=config[\"base_size\"],\n            image_size=config[\"image_size\"],\n            crop_mode=config[\"crop_mode\"],\n            save_results=False,\n            test_compress=True\n        )\n    finally:\n        sys.stdout = old_stdout\n    \n    text = captured.getvalue()\n    \n    if result and isinstance(result, (str, dict)):\n        if isinstance(result, dict) and 'text' in result:\n            return result['text']\n        if isinstance(result, str) and len(result) > 10:\n            return result\n    \n    if text:\n        lines = []\n        for line in text.split('\\n'):\n            if 'PATCHES:' in line or 'torch.Size' in line:\n                continue\n            line = re.sub(r'<\\|ref\\|>|<\\/ref>|<\\|det\\|>|<\\/det>|<\\|grounding\\|>', '', line)\n            line = re.sub(r'\\[\\[\\d+,\\s*\\d+,\\s*\\d+,\\s*\\d+\\]\\]', '', line)\n            if line.strip():\n                lines.append(line.strip())\n        return '\\n'.join(lines)\n    \n    return \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:21.692127Z","iopub.execute_input":"2026-01-22T04:25:21.692422Z","iopub.status.idle":"2026-01-22T04:25:21.701350Z","shell.execute_reply.started":"2026-01-22T04:25:21.692394Z","shell.execute_reply":"2026-01-22T04:25:21.700702Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def run_ocr(image_path: str) -> str:\n    if ACTIVE_OCR_ENGINE == OCREngine.PADDLE:\n        return run_paddle_ocr(image_path)\n    return run_deepseek_ocr(image_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:23.879483Z","iopub.execute_input":"2026-01-22T04:25:23.880230Z","iopub.status.idle":"2026-01-22T04:25:23.884467Z","shell.execute_reply.started":"2026-01-22T04:25:23.880195Z","shell.execute_reply":"2026-01-22T04:25:23.883561Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def detect_signatures(image_path: str) -> list:\n    results = signature_model(image_path)\n    return [{\"bbox\": [float(x) for x in box.tolist()], \"confidence\": float(conf)} \n            for box, conf in zip(results[0].boxes.xyxy, results[0].boxes.conf)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:25.515025Z","iopub.execute_input":"2026-01-22T04:25:25.515813Z","iopub.status.idle":"2026-01-22T04:25:25.520542Z","shell.execute_reply.started":"2026-01-22T04:25:25.515779Z","shell.execute_reply":"2026-01-22T04:25:25.519537Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def detect_stamps(image_path: str) -> list:\n    return [{\"bbox\": [0, 0, 0, 0], \"confidence\": 0.0}]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:25.806207Z","iopub.execute_input":"2026-01-22T04:25:25.806732Z","iopub.status.idle":"2026-01-22T04:25:25.810113Z","shell.execute_reply.started":"2026-01-22T04:25:25.806701Z","shell.execute_reply":"2026-01-22T04:25:25.809404Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"EXTRACTION_PROMPT = \"\"\"Extract from this invoice. Return ONLY JSON:\n{{\n    \"dealer_name\": \"company name or null\",\n    \"model_name\": \"tractor model or null\",\n    \"horse_power\": number or null,\n    \"asset_cost\": number or null\n}}\n\nOCR:\n{ocr_text}\n\nJSON:\"\"\"\n\ndef extract_fields_with_llm(ocr_text: str) -> dict:\n    default = {\"dealer_name\": None, \"model_name\": None, \"horse_power\": None, \"asset_cost\": None}\n    if not ocr_text or not ocr_text.strip():\n        return default\n    \n    prompt = EXTRACTION_PROMPT.format(ocr_text=ocr_text[:3000])\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    text = llm_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = llm_tokenizer([text], return_tensors=\"pt\").to(llm_model.device)\n    \n    with torch.no_grad():\n        out = llm_model.generate(**inputs, max_new_tokens=256, do_sample=False, pad_token_id=llm_tokenizer.eos_token_id)\n    \n    resp = llm_tokenizer.decode(out[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip()\n    \n    try:\n        if \"{\" in resp:\n            return json.loads(resp[resp.find(\"{\"):resp.rfind(\"}\")+1])\n        return json.loads(resp)\n    except:\n        return default","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:29.321832Z","iopub.execute_input":"2026-01-22T04:25:29.322127Z","iopub.status.idle":"2026-01-22T04:25:29.328777Z","shell.execute_reply.started":"2026-01-22T04:25:29.322099Z","shell.execute_reply":"2026-01-22T04:25:29.327930Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## 5. Pipeline","metadata":{}},{"cell_type":"code","source":"def process_document(image_path: str) -> dict:\n    start = time.time()\n    \n    print(f\"  ğŸ“ OCR...\", end=\" \", flush=True)\n    ocr_text = run_ocr(image_path)\n    print(f\"âœ“ ({len(ocr_text)} chars)\")\n    \n    print(\"  âœï¸  Signatures...\", end=\" \", flush=True)\n    sigs = detect_signatures(image_path)\n    print(f\"{len(sigs)} found\")\n    \n    print(\"  ğŸ¤– LLM...\", end=\" \", flush=True)\n    fields = extract_fields_with_llm(ocr_text)\n    print(\"âœ“\")\n    \n    best_sig = max(sigs, key=lambda x: x[\"confidence\"]) if sigs else None\n    \n    return {\n        \"doc_id\": Path(image_path).stem,\n        \"fields\": {\n            **fields,\n            \"signature\": {\n                \"present\": best_sig and best_sig[\"confidence\"] > 0.5,\n                \"bbox\": [int(x) for x in best_sig[\"bbox\"]] if best_sig else [0,0,0,0]\n            },\n            \"stamp\": {\"present\": False, \"bbox\": [0,0,0,0]}\n        },\n        \"processing_time_sec\": round(time.time() - start, 2),\n        \"_raw_ocr\": ocr_text[:500]\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:29.952997Z","iopub.execute_input":"2026-01-22T04:25:29.953597Z","iopub.status.idle":"2026-01-22T04:25:29.960568Z","shell.execute_reply.started":"2026-01-22T04:25:29.953565Z","shell.execute_reply":"2026-01-22T04:25:29.959461Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## 6. Run","metadata":{}},{"cell_type":"code","source":"test_image = \"/kaggle/input/doc-ocr-dataset/test/172427893_3_pg11.png\"\n\nif Path(test_image).exists():\n    print(f\"Processing: {test_image}\\n\")\n    result = process_document(test_image)\n    print(\"\\n\" + \"=\"*50)\n    print(json.dumps(result, indent=2, ensure_ascii=False))\nelse:\n    print(f\"Not found: {test_image}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:25:40.613369Z","iopub.execute_input":"2026-01-22T04:25:40.613917Z","iopub.status.idle":"2026-01-22T04:26:26.202376Z","shell.execute_reply.started":"2026-01-22T04:25:40.613885Z","shell.execute_reply":"2026-01-22T04:26:26.201581Z"}},"outputs":[{"name":"stdout","text":"Processing: /kaggle/input/doc-ocr-dataset/test/172427893_3_pg11.png\n\n  ğŸ“ OCR... ","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:1 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nThe `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\nThe attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.\n","output_type":"stream"},{"name":"stdout","text":"âœ“ (1575 chars)\n  âœï¸  Signatures... \nimage 1/1 /kaggle/input/doc-ocr-dataset/test/172427893_3_pg11.png: 640x480 2 signatures, 46.3ms\nSpeed: 4.0ms preprocess, 46.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n2 found\n  ğŸ¤– LLM... ","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"âœ“\n\n==================================================\n{\n  \"doc_id\": \"172427893_3_pg11\",\n  \"fields\": {\n    \"dealer_name\": \"IDFC FIRST BANK\",\n    \"model_name\": \"Tractor\",\n    \"horse_power\": 801815.0,\n    \"asset_cost\": 801815.0,\n    \"signature\": {\n      \"present\": true,\n      \"bbox\": [\n        222,\n        1433,\n        556,\n        1540\n      ]\n    },\n    \"stamp\": {\n      \"present\": false,\n      \"bbox\": [\n        0,\n        0,\n        0,\n        0\n      ]\n    }\n  },\n  \"processing_time_sec\": 45.58,\n  \"_raw_ocr\": \"=====================\\n=====================\\ntitle<|/ref|><|/det|>\\n# QUOTATION\\ntitle<|/ref|><|/det|>\\n# The Odisha Agro Industries Corporation Ltd.\\ntext<|/ref|><|/det|>\\n(A Govt. of Odisha Undertaking)\\ntext<|/ref|><|/det|>\\nOFFICE OF THE DISTRICT MANAGER (PURI)\\ntext<|/ref|><|/det|>\\nSAKHIGOPAL,PURI,PIN- 752046.MAILID- dinpurir@orissagro.com\\ntable<|/ref|><|/det|>\\n<table><tr><td colspan=\\\"4\\\">Financed By: IDFC FIRST BANK.</td></tr><tr><td>SINo</td><td>Description</td><td>Qnty</td><td>Amount</td></tr><tr>\"\n}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## 7. Batch","metadata":{}},{"cell_type":"code","source":"def process_folder(folder_path: str, output_file: str = \"results.json\") -> list:\n    images = list(Path(folder_path).glob(\"*.png\")) + list(Path(folder_path).glob(\"*.jpg\"))\n    print(f\"ğŸ“ {len(images)} images\\n\")\n    \n    results = []\n    for i, img in enumerate(images, 1):\n        print(f\"[{i}/{len(images)}] {img.name}\")\n        try:\n            results.append(process_document(str(img)))\n        except Exception as e:\n            results.append({\"doc_id\": img.stem, \"error\": str(e)})\n    \n    with open(output_file, \"w\") as f:\n        json.dump(results, f, indent=2)\n    print(f\"\\nâœ“ Saved to {output_file}\")\n    return results\n\nresults = process_folder(\"/kaggle/input/doc-ocr-dataset/test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T04:27:17.750205Z","iopub.execute_input":"2026-01-22T04:27:17.750775Z"}},"outputs":[{"name":"stdout","text":"ğŸ“ 10 images\n\n[1/10] 172585685_3_pg1.png\n  ğŸ“ OCR... ","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"âœ“ (2556 chars)\n  âœï¸  Signatures... \nimage 1/1 /kaggle/input/doc-ocr-dataset/test/172585685_3_pg1.png: 640x512 1 signature, 46.4ms\nSpeed: 2.6ms preprocess, 46.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n1 found\n  ğŸ¤– LLM... âœ“\n[2/10] 172448470_3_pg15.png\n  ğŸ“ OCR... ","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n","output_type":"stream"}],"execution_count":null}]}